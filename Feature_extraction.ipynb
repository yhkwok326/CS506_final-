{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e93b58",
   "metadata": {},
   "source": [
    "# Data normalization and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0881fa-17af-4042-8581-c68cdeafa701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_and_normalize_dataset(base_dir):\n",
    "    normalized_data = []\n",
    "    \n",
    "    # Class mapping\n",
    "    classes = {\n",
    "        'Mild_Demented': 0,\n",
    "        'Moderate_Demented': 1,\n",
    "        'Non_Demented': 2,\n",
    "        'Very_Mild_Demented': 3\n",
    "    }\n",
    "    \n",
    "    # Process train, test, and val folders\n",
    "    for split in ['train', 'test', 'val']:\n",
    "        split_dir = os.path.join(base_dir, split)\n",
    "        \n",
    "        if not os.path.exists(split_dir):\n",
    "            print(f\"Warning: {split_dir} does not exist, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Process each class folder\n",
    "        for class_name, label in classes.items():\n",
    "            class_dir = os.path.join(split_dir, class_name)\n",
    "            \n",
    "            if not os.path.exists(class_dir):\n",
    "                continue\n",
    "                \n",
    "            # Process each image in the class folder\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, img_file)\n",
    "                    \n",
    "                    try:\n",
    "                        # Load image\n",
    "                        img = Image.open(img_path).convert('L')\n",
    "                        img_array = np.array(img) / 255.0  # Normalize to [0,1]\n",
    "                        \n",
    "                        # Process and store\n",
    "                        item = {\n",
    "                            'original_path': img_path,\n",
    "                            'label': label,\n",
    "                            'class_name': class_name,\n",
    "                            'split': split,\n",
    "                            'image': img_array,\n",
    "                            'dataset': 'folder_dataset' if 'folder' in img_file else 'parquet_dataset'\n",
    "                        }\n",
    "                        \n",
    "                        # Apply normalizations\n",
    "                        normalized_item = normalize_mri_for_ventricles(item, contours=True) # added parameter to inclue isolated ventricles\n",
    "                        normalized_data.append(normalized_item)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    # Split back into train, test, and val\n",
    "    train_data = [item for item in normalized_data if item['split'] == 'train']\n",
    "    test_data = [item for item in normalized_data if item['split'] == 'test']\n",
    "    val_data = [item for item in normalized_data if item['split'] == 'val']\n",
    "    \n",
    "    return train_data, test_data, val_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92e140-80f1-4a5c-a9a5-ebe65376ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_mri_for_ventricles(item, contours=False): # added parameter contours\n",
    "    \"\"\"\n",
    "    Feature extraction : Ventricles \n",
    "    \"\"\"\n",
    "    image = item['image']\n",
    "    \n",
    "    # 1. Intensity normalization (robust)\n",
    "    brain_mask = image > 0.05\n",
    "    brain_pixels = image[brain_mask]\n",
    "    \n",
    "    if len(brain_pixels) > 0:\n",
    "        p2, p98 = np.percentile(brain_pixels, [2, 98])\n",
    "        normalized = np.clip(image, p2, p98)\n",
    "        normalized = (normalized - p2) / (p98 - p2)\n",
    "        item['image_normalized'] = normalized\n",
    "    else:\n",
    "        item['image_normalized'] = image\n",
    "    \n",
    "    # 2. Ventricle enhancement\n",
    "    \n",
    "    # Create version optimized for dark ventricle regions\n",
    "    img_uint8 = (item['image_normalized'] * 255).astype(np.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(img_uint8)\n",
    "    item['image_enhanced'] = enhanced / 255.0\n",
    "    \n",
    "    # Create inverted version to highlight ventricles\n",
    "    inverted = 1 - item['image_normalized']\n",
    "    # Apply adaptive thresholding to highlight ventricle regions\n",
    "    item['image_ventricle_focus'] = inverted\n",
    "    \n",
    "    # 3. Ventricle segmentation (rough approximation)\n",
    "    # Threshold to isolate ventricles (dark regions)\n",
    "    _, threshold = cv2.threshold(\n",
    "        img_uint8, \n",
    "        int(np.mean(img_uint8) * 0.5), \n",
    "        255, \n",
    "        cv2.THRESH_BINARY_INV\n",
    "    )\n",
    "    \n",
    "    # Clean up mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(threshold, cv2.MORPH_OPEN, kernel) # i changed the variables to make it more clear\n",
    "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel) # cleaned is the ventricle mask \n",
    "    \n",
    "    item['ventricle_mask'] = cleaned / 255.0\n",
    "        \n",
    "    if contours:\n",
    "    # Suggestion: Extract only the ventricles using contors \n",
    "        contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = sorted(contours,key=cv2.contourArea,reverse=True)[:2] # Only keeping the two assuming the two largest are the ventricles need to double check \n",
    "        enhanced_rgb = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR)\n",
    "        contour_img = enhanced_rgb.copy()\n",
    "        cv2.drawContours(contour_img, contours, -1, (0, 255, 0), 2)\n",
    "        item['contour_img'] = contour_img\n",
    "    # Now get the venctricles, drawing the contours on a blank mask and then applying the mask to the image\n",
    "    # Everything should be black except the ventricles\n",
    "        blank_mask = np.zeros_like(enhanced, dtype=np.uint8)\n",
    "        cv2.drawContours(blank_mask,contours,-1,255,thickness=cv2.FILLED)\n",
    "        ventricles = cv2.bitwise_and(enhanced, enhanced, mask=blank_mask) \n",
    "        item['ventricles'] = ventricles / 255.0 if ventricles.max() > 1 else ventricles\n",
    "        \n",
    "    return item \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c7cc2c",
   "metadata": {},
   "source": [
    "i haven't tested the code yet and haven't added it to the visualization part yet, we should though to see if the contours correctly maps out the ventricles, aka visualize contour_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "434ca0f7-3888-483f-a9f2-d290eb3ef7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_normalizations(data, num_samples=4):\n",
    "    \"\"\"\n",
    "    Can comment this function out \n",
    "    \"\"\"\n",
    "    # Select samples from each class if possible\n",
    "    samples = []\n",
    "    classes = set(item['class_name'] for item in data)\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_items = [item for item in data if item['class_name'] == class_name]\n",
    "        if class_items:\n",
    "            samples.append(class_items[0])\n",
    "            if len(samples) >= num_samples:\n",
    "                break\n",
    "    \n",
    "    # Use random samples if we don't have enough\n",
    "    if len(samples) < num_samples:\n",
    "        additional = np.random.choice(\n",
    "            [i for i in data if i not in samples],\n",
    "            size=min(num_samples - len(samples), len(data) - len(samples)),\n",
    "            replace=False\n",
    "        ).tolist()\n",
    "        samples.extend(additional)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(len(samples), 4, figsize=(16, 4 * len(samples)))\n",
    "    \n",
    "    for i, item in enumerate(samples):\n",
    "        # Original\n",
    "        axes[i, 0].imshow(item['image'], cmap='gray')\n",
    "        axes[i, 0].set_title(f\"{item['class_name']}\\nOriginal\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Normalized\n",
    "        axes[i, 1].imshow(item['image_normalized'], cmap='gray')\n",
    "        axes[i, 1].set_title('Normalized')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Enhanced\n",
    "        axes[i, 2].imshow(item['image_enhanced'], cmap='gray')\n",
    "        axes[i, 2].set_title('Enhanced')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # Ventricle Focus (Inverted)\n",
    "        axes[i, 3].imshow(item['image_ventricle_focus'], cmap='gray')\n",
    "        axes[i, 3].set_title('Ventricle Focus')\n",
    "        axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab592994-f93b-49c0-9966-27e3ef42756c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and normalizing dataset...\n",
      "Processed 15360 training images, 3584 test images, and 1152 validation images\n",
      "Generating visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving train images: 100%|██████████████| 15360/15360 [00:13<00:00, 1143.40it/s]\n",
      "Saving test images: 100%|█████████████████| 3584/3584 [00:03<00:00, 1145.97it/s]\n",
      "Saving val images: 100%|██████████████████| 1152/1152 [00:01<00:00, 1051.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TA-DA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def save_normalized_dataset(base_dir, train_data, test_data, val_data):\n",
    "    \n",
    "    # Create output directories\n",
    "    output_dir = os.path.join(base_dir, 'normalized')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    for split, data in [('train', train_data), ('test', test_data), ('val', val_data)]:\n",
    "        split_dir = os.path.join(output_dir, split)\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "        \n",
    "        # Create class directories\n",
    "        class_names = set(item['class_name'] for item in data)\n",
    "        for class_name in class_names:\n",
    "            os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n",
    "        \n",
    "        # Save normalized images\n",
    "        for item in tqdm(data, desc=f\"Saving {split} images\"):\n",
    "            # Generate filename\n",
    "            original_filename = os.path.basename(item['original_path'])\n",
    "            base_name = os.path.splitext(original_filename)[0]\n",
    "            \n",
    "            # Define paths for different normalizations\n",
    "            class_dir = os.path.join(split_dir, item['class_name'])\n",
    "            \n",
    "            # Save normalized image\n",
    "            norm_img = (item['image_normalized'] * 255).astype(np.uint8)\n",
    "            norm_path = os.path.join(class_dir, f\"{base_name}_norm.png\")\n",
    "            Image.fromarray(norm_img).save(norm_path)\n",
    "            \n",
    "            # Save ventricle focused image (better for ventricle analysis)\n",
    "            ventricle_img = (item['image_ventricle_focus'] * 255).astype(np.uint8)\n",
    "            ventricle_path = os.path.join(class_dir, f\"{base_name}_ventricle.png\")\n",
    "            Image.fromarray(ventricle_img).save(ventricle_path)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the base directory to your combined dataset\n",
    "    base_dir = \"Combined_MRI_Dataset\"\n",
    "    \n",
    "    # Load and normalize the dataset\n",
    "    print(\"Loading and normalizing dataset...\")\n",
    "    train_data, test_data, val_data = load_and_normalize_dataset(base_dir)\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"Processed {len(train_data)} training images, {len(test_data)} test images, and {len(val_data)} validation images\")\n",
    "    \n",
    "    # Visualize normalizations\n",
    "    print(\"Generating visualization...\")\n",
    "    fig = visualize_normalizations(train_data + test_data + val_data)\n",
    "    plt.savefig(os.path.join(base_dir, \"normalization_visualization.png\"))\n",
    "    plt.close(fig)\n",
    "    \n",
    "    save_normalized_dataset(base_dir, train_data, test_data, val_data)\n",
    "    \n",
    "    print(\"TA-DA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8551a30b",
   "metadata": {},
   "source": [
    "nextsteps:\n",
    "feature extraction - ventricles:\n",
    "plan is to layer these hancrafted features with original image/cnn features to increase accuracy if possible, below are just possible features we can choose from\n",
    "\n",
    "Size-related features:\n",
    "    Pixel count (area of ventricles) → Measures how large the ventricles are.\n",
    "    Perimeter (boundary length) → Tells how irregular the ventricle shape is.\n",
    "    Major/Minor axis lengths → Captures the elongation of the ventricles.\n",
    "\n",
    "Shape-related features:\n",
    "    Eccentricity → Measures how oval the ventricles are.\n",
    "    Circularity → Helps differentiate between normal and abnormal ventricle shapes.\n",
    "\n",
    "Texture-related features:\n",
    "    Entropy → Measures randomness in intensity distribution (higher entropy may indicate pathology).\n",
    "    Gray-Level Co-occurrence Matrix (GLCM) → Captures patterns of pixel intensities (e.g., roughness).\n",
    "\n",
    "how about other areas of the scan? hippocampus?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301cd5e-bf7f-4024-896c-da1ec1960ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
