{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa1923a-60d6-4848-93e3-32048d4009e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and normalizing dataset...\n",
      "Processing train/Mild_Demented...\n",
      "Processing train/Moderate_Demented...\n",
      "Processing train/Non_Demented...\n",
      "Processing train/Very_Mild_Demented...\n",
      "Processing test/Mild_Demented...\n",
      "Processing test/Moderate_Demented...\n",
      "Processing test/Non_Demented...\n",
      "Processing test/Very_Mild_Demented...\n",
      "Processing val/Mild_Demented...\n",
      "Processing val/Moderate_Demented...\n",
      "Processing val/Non_Demented...\n",
      "Processing val/Very_Mild_Demented...\n",
      "Processed 12543 training images, 3584 test images, and 1792 validation images\n",
      "\n",
      "Training set class distribution:\n",
      "  Mild_Demented: 2545 images (20.3%)\n",
      "  Moderate_Demented: 1845 images (14.7%)\n",
      "  Non_Demented: 4480 images (35.7%)\n",
      "  Very_Mild_Demented: 3673 images (29.3%)\n",
      "\n",
      "Test set class distribution:\n",
      "  Mild_Demented: 727 images (20.3%)\n",
      "  Moderate_Demented: 527 images (14.7%)\n",
      "  Non_Demented: 1280 images (35.7%)\n",
      "  Very_Mild_Demented: 1050 images (29.3%)\n",
      "\n",
      "Validation set class distribution:\n",
      "  Mild_Demented: 363 images (20.3%)\n",
      "  Moderate_Demented: 264 images (14.7%)\n",
      "  Non_Demented: 640 images (35.7%)\n",
      "  Very_Mild_Demented: 525 images (29.3%)\n",
      "\n",
      "Generating visualization...\n",
      "\n",
      "Saving normalized dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving train images: 100%|███████████████| 12543/12543 [00:18<00:00, 682.42it/s]\n",
      "Saving test images: 100%|██████████████████| 3584/3584 [00:05<00:00, 682.52it/s]\n",
      "Saving val images: 100%|███████████████████| 1792/1792 [00:02<00:00, 688.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 17919 images processed and saved with normalizations\n",
      "\n",
      "Feature extraction complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_and_normalize_dataset(base_dir):\n",
    "    normalized_data = []\n",
    "    \n",
    "    classes = {\n",
    "        'Mild_Demented': 0,\n",
    "        'Moderate_Demented': 1,\n",
    "        'Non_Demented': 2,\n",
    "        'Very_Mild_Demented': 3\n",
    "    }\n",
    "    \n",
    "    # Process train, test, and val folders\n",
    "    for split in ['train', 'test', 'val']:\n",
    "        split_dir = os.path.join(base_dir, split)\n",
    "        \n",
    "        if not os.path.exists(split_dir):\n",
    "            print(f\"Warning: {split_dir} does not exist, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Process each class folder\n",
    "        for class_name, label in classes.items():\n",
    "            class_dir = os.path.join(split_dir, class_name)\n",
    "            \n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"Warning: Class directory {class_dir} does not exist, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            # Process each image in the class folder\n",
    "            print(f\"Processing {split}/{class_name}...\")\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, img_file)\n",
    "                    \n",
    "                    try:\n",
    "                        # Load image\n",
    "                        img = Image.open(img_path).convert('L')\n",
    "                        img_array = np.array(img) / 255.0  # Normalize to [0,1]\n",
    "                        \n",
    "                        # Process and store\n",
    "                        item = {\n",
    "                            'original_path': img_path,\n",
    "                            'label': label,\n",
    "                            'class_name': class_name,\n",
    "                            'split': split,\n",
    "                            'image': img_array,\n",
    "                            'dataset': 'folder_dataset' if 'folder' in img_file else 'parquet_dataset'\n",
    "                        }\n",
    "                        \n",
    "                        # Apply normalizations\n",
    "                        normalized_item = normalize_mri_for_ventricles(item)\n",
    "                        normalized_data.append(normalized_item)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {img_path}: {e}\")\n",
    "    \n",
    "    # Split back into train, test, and val\n",
    "    train_data = [item for item in normalized_data if item['split'] == 'train']\n",
    "    test_data = [item for item in normalized_data if item['split'] == 'test']\n",
    "    val_data = [item for item in normalized_data if item['split'] == 'val']\n",
    "    \n",
    "    return train_data, test_data, val_data\n",
    "\n",
    "def normalize_mri_for_ventricles(item):\n",
    "    image = item['image']\n",
    "    \n",
    "    # 1. Simple normalization - just use the original normalized image\n",
    "    item['image_normalized'] = image\n",
    "    \n",
    "    # 2. Ventricle enhancement\n",
    "    \n",
    "    # Create version optimized for dark ventricle regions\n",
    "    img_uint8 = (item['image_normalized'] * 255).astype(np.uint8)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(img_uint8)\n",
    "    item['image_enhanced'] = enhanced / 255.0\n",
    "    \n",
    "    # Create inverted version to highlight ventricles\n",
    "    inverted = 1 - item['image_normalized']\n",
    "    # Apply adaptive thresholding to highlight ventricle regions\n",
    "    item['image_ventricle_focus'] = inverted\n",
    "    \n",
    "    # 3. Ventricle segmentation using Otsu thresholding\n",
    "    otsu_thresh, _ = cv2.threshold(\n",
    "        img_uint8, \n",
    "        0, \n",
    "        255, \n",
    "        cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU\n",
    "    )\n",
    "\n",
    "    \n",
    "    _, ventricle_mask = cv2.threshold(\n",
    "        img_uint8, \n",
    "        int(otsu_thresh * 0.5),   \n",
    "        255, \n",
    "        cv2.THRESH_BINARY_INV\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Clean up mask\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    ventricle_mask = cv2.morphologyEx(ventricle_mask, cv2.MORPH_OPEN, kernel)\n",
    "    ventricle_mask = cv2.morphologyEx(ventricle_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    item['ventricle_mask'] = ventricle_mask / 255.0\n",
    "    \n",
    "    return item\n",
    "\n",
    "def visualize_normalizations(data, num_samples=4):\n",
    "   \n",
    "    samples = []\n",
    "    classes = set(item['class_name'] for item in data)\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_items = [item for item in data if item['class_name'] == class_name]\n",
    "        if class_items:\n",
    "            samples.append(class_items[0])\n",
    "            if len(samples) >= num_samples:\n",
    "                break\n",
    "    \n",
    "    # Use random samples if we don't have enough\n",
    "    if len(samples) < num_samples:\n",
    "        remaining = [i for i in data if not any(s['original_path'] == i['original_path'] for s in samples)]\n",
    "        if remaining:\n",
    "            additional = np.random.choice(\n",
    "                remaining,\n",
    "                size=min(num_samples - len(samples), len(remaining)),\n",
    "                replace=False\n",
    "            ).tolist()\n",
    "            samples.extend(additional)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(len(samples), 5, figsize=(20, 4 * len(samples)))\n",
    "    \n",
    "    # Handle case with just one sample\n",
    "    if len(samples) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, item in enumerate(samples):\n",
    "        # Original\n",
    "        axes[i][0].imshow(item['image'], cmap='gray')\n",
    "        axes[i][0].set_title(f\"{item['class_name']}\\nOriginal\")\n",
    "        axes[i][0].axis('off')\n",
    "        \n",
    "        # Normalized\n",
    "        axes[i][1].imshow(item['image_normalized'], cmap='gray')\n",
    "        axes[i][1].set_title('Normalized')\n",
    "        axes[i][1].axis('off')\n",
    "        \n",
    "        # Enhanced\n",
    "        axes[i][2].imshow(item['image_enhanced'], cmap='gray')\n",
    "        axes[i][2].set_title('Enhanced (CLAHE)')\n",
    "        axes[i][2].axis('off')\n",
    "        \n",
    "        # Ventricle Focus (Inverted)\n",
    "        axes[i][3].imshow(item['image_ventricle_focus'], cmap='gray')\n",
    "        axes[i][3].set_title('Ventricle Focus')\n",
    "        axes[i][3].axis('off')\n",
    "        \n",
    "        # Ventricle Mask\n",
    "        axes[i][4].imshow(item['ventricle_mask'], cmap='gray')\n",
    "        axes[i][4].set_title('Ventricle Mask')\n",
    "        axes[i][4].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def save_normalized_dataset(base_dir, train_data, test_data, val_data):\n",
    "     \n",
    "    # Create output directories\n",
    "    output_dir = os.path.join(base_dir, 'normalized')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    saved_count = 0\n",
    "    \n",
    "    for split, data in [('train', train_data), ('test', test_data), ('val', val_data)]:\n",
    "        split_dir = os.path.join(output_dir, split)\n",
    "        os.makedirs(split_dir, exist_ok=True)\n",
    "        \n",
    "        # Create class directories\n",
    "        class_names = set(item['class_name'] for item in data)\n",
    "        for class_name in class_names:\n",
    "            os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n",
    "        \n",
    "        # Save normalized images\n",
    "        for item in tqdm(data, desc=f\"Saving {split} images\"):\n",
    "            # Generate filename\n",
    "            original_filename = os.path.basename(item['original_path'])\n",
    "            base_name = os.path.splitext(original_filename)[0]\n",
    "            \n",
    "            # Define paths for different normalizations\n",
    "            class_dir = os.path.join(split_dir, item['class_name'])\n",
    "            \n",
    "            # Save normalized image\n",
    "            norm_img = (item['image_normalized'] * 255).astype(np.uint8)\n",
    "            norm_path = os.path.join(class_dir, f\"{base_name}_norm.png\")\n",
    "            Image.fromarray(norm_img).save(norm_path)\n",
    "            \n",
    "            # Save enhanced image\n",
    "            enhanced_img = (item['image_enhanced'] * 255).astype(np.uint8)\n",
    "            enhanced_path = os.path.join(class_dir, f\"{base_name}_enhanced.png\")\n",
    "            Image.fromarray(enhanced_img).save(enhanced_path)\n",
    "            \n",
    "            # Save ventricle focused image\n",
    "            ventricle_img = (item['image_ventricle_focus'] * 255).astype(np.uint8)\n",
    "            ventricle_path = os.path.join(class_dir, f\"{base_name}_ventricle.png\")\n",
    "            Image.fromarray(ventricle_img).save(ventricle_path)\n",
    "            \n",
    "            # Save ventricle mask\n",
    "            mask_img = (item['ventricle_mask'] * 255).astype(np.uint8)\n",
    "            mask_path = os.path.join(class_dir, f\"{base_name}_mask.png\")\n",
    "            Image.fromarray(mask_img).save(mask_path)\n",
    "            \n",
    "            saved_count += 1\n",
    "    \n",
    "    print(f\"Total of {saved_count} images processed and saved with normalizations\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    base_dir = \"Combined_MRI_Dataset\"\n",
    "    \n",
    "    print(\"Loading and normalizing dataset...\")\n",
    "    train_data, test_data, val_data = load_and_normalize_dataset(base_dir)\n",
    "    \n",
    "    print(f\"Processed {len(train_data)} training images, {len(test_data)} test images, and {len(val_data)} validation images\")\n",
    "    \n",
    "    # Class distribution summary\n",
    "    for split_name, split_data in [(\"Training\", train_data), (\"Test\", test_data), (\"Validation\", val_data)]:\n",
    "        print(f\"\\n{split_name} set class distribution:\")\n",
    "        class_counts = {}\n",
    "        for item in split_data:\n",
    "            class_name = item['class_name']\n",
    "            if class_name in class_counts:\n",
    "                class_counts[class_name] += 1\n",
    "            else:\n",
    "                class_counts[class_name] = 1\n",
    "        \n",
    "        for class_name, count in class_counts.items():\n",
    "            print(f\"  {class_name}: {count} images ({count/len(split_data)*100:.1f}%)\")\n",
    "    \n",
    "    # Visualize normalizations\n",
    "    print(\"\\nGenerating visualization...\")\n",
    "    fig = visualize_normalizations(train_data)\n",
    "    plt.savefig(os.path.join(base_dir, \"normalization_visualization.png\"))\n",
    "    plt.close(fig)\n",
    "    \n",
    "    # Save normalized dataset\n",
    "    print(\"\\nSaving normalized dataset...\")\n",
    "    save_normalized_dataset(base_dir, train_data, test_data, val_data)\n",
    "    \n",
    "    print(\"\\nFeature extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c5e9ae-4284-43bc-a86e-4fccf862dd23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
